%
% TÍTULO DEL CAPÍTULO
%
\chapter{Conclusions and future lines of work
	\label{chapter_5}
}

In this chapter we will briefly take a look at the conclusions reached after finishing this project, and the possible future lines of work that the project can follow.

\section[Conclusions]{Conclusions}

The first conclusion reached, has been that all of the objectives of the project were met:

\begin{itemize}
\item Studying different Stereo Matching techniques.
\item Design, implementation and documentation of tools to ease GPGPU programming.
\item Design, implementation and documentation of the chosen algorithm. 
\item CPU parallelization of the implemented algorithm.
\item GPU parallelization of the implemented algorithm.
\end{itemize}

After finishing and achieving all the aforementioned objectives, the other conclusions that have been reached are:

\begin{itemize}
\item \textbf{GPGPU is not always the answer:} As seen in the results, if the workload is not complex enough to compensate for kernel setup time, GPU computation time will be higher than the time it takes the CPU to process the data. One has to carefully consider if the workload and the chosen algorithms are optimal for GPU parallelization or a lot of time can be wasted.
\item \textbf{GPGPU tools significantly speed up the development process:} Creating multi-platform OpenCL and CUDA algorithms is not a trivial task. Without the help of this library the implementation of the algorithms would be error prone and slower.
\item \textbf{GPGPU device selection is complex:} The automatic selection of the best GPU computing device, is not an easy task. Improvements in architecture, clock speed, etc. can render devices with more compute units obsolete; making it difficult to automatically guess the best device. This is specially complex in OpenCL, because of the variety of devices present in the ecosystem.
\item \textbf{GPGPU improves performance substantially:} In Computer Vision tasks GPU computing fits really well. In a wide variety of algorithms, the workloads are highly parallel; allowing us to squeeze the maximum amount of processing power out of GPUs.
\end{itemize} 

\section[Future lines of work]{Future lines of work}

After finalizing the work on this project, several ideas for the expansion of the library come to mind:

\begin{itemize}
\item \textbf{GPU kernels optimization:} As of know the implemented kernels of the Block Matching algorithm are semi-naive implementations. It would be interesting to further optimize these kernels so they would use local memory and would access the data with more optimal patterns or other types of improvements.
\item \textbf{Multi-GPU:} As of now, the GPU algorithms and tools are designed to work on a single GPU device. The next step could be the adaptation of the algorithms to work on multiple GPUs. This would increment the performance gap even further against CPUs.
\item \textbf{MPI tools:} Since this is a GPU computing library, we have not delved into the usage of MPI to parallelize the algorithms. But in HPC, the usage of supercomputers sometimes requires MPI implementations. The creation of helper tools and their integration in multi-platform systems could be an interesting step forward.
\item \textbf{Boost Compute:} The usage of this library for the OpenCL module, could provide STL-like common algorithms, common containers and iterators (for example, vectors, etc.). 
\item \textbf{Thrust:} As in the proposed OpenCL module aforementioned improvement, in CUDA we could use Thrust to achieve a similar result.
\item \textbf{Optimization of the algorithm:} The improvement of the algorithm in terms of performance using message passing techniques, could also yield improvements for the CPU and GPU implementations.
\item \textbf{Block Matching:} To improve the block matching algorithm, new correlation based similarity measures should be implemented. Several algorithm improvements could also be made to improve CPU and GPU computing times.
\end{itemize} 
